{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI-QC\n",
    "https://mriqc.readthedocs.io/en/latest/docker.html#docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run -it nipreps/mriqc:latest --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the participant level in subjects 001 002 003\n",
    "\n",
    "If the argument `--participant_label` is not provided, then all subjects will be processed and the group level analysis will automatically be executed without need of running the command in item 3.\n",
    "\n",
    "Paths `<bids_dir>` and `<output_dir>` must be absolute. In particular, specifying relative paths for `<output_dir>` will generate no error and mriqc will run to completion without error but produce no output.\n",
    "\n",
    "For security reasons, we recommend to run the docker command with the options `--read-only --tmpfs /run --tmpfs /tmp`. This will run the docker image in read-only mode, and map the temporary folders `/run` and `/tmp` to the temporal folder of the host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# default\n",
    "docker run -it --rm -v <bids_dir>:/data:ro -v <output_dir>:/out nipreps/mriqc:latest /data /out participant --participant_label 001 002 003\n",
    "# with my paths\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v3_bids:/data:ro -v /home/jaimebarranco/Desktop/mriqc_output:/out nipreps/mriqc:latest /data /out participant --participant_label 001 002 003\n",
    "# handle performance\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v3_bids:/data:ro -v /home/jaimebarranco/Desktop/mriqc_output:/out nipreps/mriqc:latest /data /out participant --nprocs 8 --omp-nthreads 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the group level and report generation on previously processed (use the same `<output_dir>`) subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# default\n",
    "docker run -it --rm -v <bids_dir>:/data:ro -v <output_dir>:/out nipreps/mriqc:latest /data /out group #--read-only --tmpfs /run --tmpfs /tmp\n",
    "# with my paths\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v2_bids:/data:ro -v /home/jaimebarranco/Desktop/mriqc_output:/out nipreps/mriqc:latest /data /out group #--read-only --tmpfs /run --tmpfs /tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop of individual participants\n",
    "And group report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "# def run_command(command):\n",
    "#     process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "#     console_output, console_errors = process.communicate()\n",
    "\n",
    "def run_command(command):\n",
    "    os.system(command)\n",
    "\n",
    "input_folder = '/home/jaimebarranco/Desktop/samples_v3_bids'\n",
    "output_folder = '/home/jaimebarranco/Desktop/mriqc_output'\n",
    "n_procs = 12\n",
    "n_threads = 12\n",
    "\n",
    "n_sub = [f.path for f in os.scandir(input_folder) if f.is_dir() and f.name.startswith('sub-')] # number of subjects in input folder\n",
    "n_sub = len(n_sub)\n",
    "print(f'Number of subjects: {n_sub}')\n",
    "\n",
    "# Run MRIQC for each subject\n",
    "for sub in range(6, n_sub):\n",
    "    command = f'docker run --rm -v {input_folder}:/data:ro -v {output_folder}:/out nipreps/mriqc:latest /data /out participant --participant_label {sub+1:03} --nprocs {n_procs} --omp-nthreads {n_threads}'\n",
    "    print(command)\n",
    "    run_command(command)\n",
    "\n",
    "# Run MRIQC group analysis\n",
    "command = f'docker run --rm -v {input_folder}:/data:ro -v {output_folder}:/out nipreps/mriqc:latest /data /out group'\n",
    "print(command)\n",
    "run_command(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics correlation\n",
    "Meri's subjective scores vs IQMs (Image Quality Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='samples_v3')\n",
    "\n",
    "# metrics\n",
    "meri = df['quality'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
