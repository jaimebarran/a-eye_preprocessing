{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI-QC\n",
    "https://mriqc.readthedocs.io/en/latest/docker.html#docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run -it nipreps/mriqc:latest --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the participant level in subjects 001 002 003\n",
    "\n",
    "If the argument `--participant_label` is not provided, then all subjects will be processed and the group level analysis will automatically be executed without need of running the command in item 3.\n",
    "\n",
    "Paths `<bids_dir>` and `<output_dir>` must be absolute. In particular, specifying relative paths for `<output_dir>` will generate no error and mriqc will run to completion without error but produce no output.\n",
    "\n",
    "For security reasons, we recommend to run the docker command with the options `--read-only --tmpfs /run --tmpfs /tmp`. This will run the docker image in read-only mode, and map the temporary folders `/run` and `/tmp` to the temporal folder of the host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# default\n",
    "docker run -it --rm -v <bids_dir>:/data:ro -v <output_dir>:/out nipreps/mriqc:latest /data /out participant --participant_label 001 002 003\n",
    "# with my paths\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v3_bids:/data:ro -v /home/jaimebarranco/Desktop/mriqc_output:/out nipreps/mriqc:latest /data /out participant --participant_label 001 002 003\n",
    "# handle performance\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v3_bids:/data:ro -v /home/jaimebarranco/Desktop/mriqc_output:/out nipreps/mriqc:latest /data /out participant --participant_label 001 --nprocs 12 --omp-nthreads 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the group level and report generation on previously processed (use the same `<output_dir>`) subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# default\n",
    "docker run -it --rm -v <bids_dir>:/data:ro -v <output_dir>:/out nipreps/mriqc:latest /data /out group #--read-only --tmpfs /run --tmpfs /tmp\n",
    "# with my paths\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v2_bids:/data:ro -v /home/jaimebarranco/Desktop/mriqc_output:/out nipreps/mriqc:latest /data /out group #--read-only --tmpfs /run --tmpfs /tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop of individual participants\n",
    "And group report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "# def run_command(command):\n",
    "#     process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "#     console_output, console_errors = process.communicate()\n",
    "\n",
    "def run_command(command):\n",
    "    os.system(command)\n",
    "\n",
    "input_folder = '/home/jaimebarranco/Desktop/samples_v3_bids'\n",
    "output_folder = '/home/jaimebarranco/Desktop/mriqc_output'\n",
    "n_procs = 12\n",
    "n_threads = 12\n",
    "\n",
    "n_sub = [f.path for f in os.scandir(input_folder) if f.is_dir() and f.name.startswith('sub-')] # number of subjects in input folder\n",
    "n_sub = len(n_sub)\n",
    "print(f'Number of subjects: {n_sub}')\n",
    "\n",
    "# Run MRIQC for each subject\n",
    "for sub in range(6, n_sub):\n",
    "    command = f'docker run --rm -v {input_folder}:/data:ro -v {output_folder}:/out nipreps/mriqc:latest /data /out participant --participant_label {sub+1:03} --nprocs {n_procs} --omp-nthreads {n_threads}'\n",
    "    print(command)\n",
    "    run_command(command)\n",
    "\n",
    "# Run MRIQC group analysis\n",
    "command = f'docker run --rm -v {input_folder}:/data:ro -v {output_folder}:/out nipreps/mriqc:latest /data /out group'\n",
    "print(command)\n",
    "run_command(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics correlation\n",
    "Meri's subjective scores vs IQMs (Image Quality Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='samples_v3')\n",
    "\n",
    "# metrics\n",
    "meri = df['quality'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% confidence interval: qi_2, summary_bg_mad, summary_gm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects outside the 95% confidence interval for qi_2\n",
    "relevant_metrics = [qi_2, summary_bg_mad, summary_gm_mean]\n",
    "relevant_metrics_name = ['qi_2', 'summary_bg_mad', 'summary_gm_mean']\n",
    "\n",
    "for i in range(len(relevant_metrics)):\n",
    "    print(f'\\n{relevant_metrics_name[i]}')\n",
    "    mean = np.mean(relevant_metrics[i])\n",
    "    std = np.std(relevant_metrics[i])\n",
    "    lower = mean - 2*std\n",
    "    upper = mean + 2*std\n",
    "    print(f'Lower: {lower}, Upper: {upper}')\n",
    "    for j in range(len(relevant_metrics[i])):\n",
    "        if relevant_metrics[i][j] < lower or relevant_metrics[i][j] > upper:\n",
    "            print(f'{j+1:03} - {relevant_metrics[i][j]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetal Brain QC (Thomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# usage: qc_list_bids_csv [-h] [--mask-patterns MASK_PATTERNS [MASK_PATTERNS ...]] [--out-csv OUT_CSV] [--anonymize-name | --no-anonymize-name] bids-dir\n",
    "qc_list_bids_csv --mask-patterns-base /home/jaimebarranco/Desktop/samples_v3_bids/derivatives/masks/ --mask-patterns \"sub-{subject}_mask.nii.gz\" --out-csv /home/jaimebarranco/Desktop/fetal_qc_output/bids_csv.csv /home/jaimebarranco/Desktop/samples_v3_bids\n",
    "qc_list_bids_csv --mask-patterns-base /home/jaimebarranco/Desktop/samples_v3_bids/derivatives/masks/ --mask-patterns \"sub-{subject}_mask.nii.gz\" --out-csv /home/jaimebarranco/Desktop/fetal_qc_output/bids_csv.csv /home/jaimebarranco/Desktop/samples_v3_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "qc_run_pipeline --bids_dir /home/jaimebarranco/Desktop/samples_v3_bids --out_path /home/jaimebarranco/Desktop/fetal_qc_output/ --mask-patterns-base /home/jaimebarranco/Desktop/samples_v3_bids/derivatives/masks/ --mask-patterns \"_mask.nii.gz\"\n",
    "qc_run_pipeline --bids_dir /home/jaimebarranco/Desktop/samples_v3_bids --out_path /home/jaimebarranco/Desktop/fetal_qc_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Thomas commands - branch mreye\n",
    "# being in the data folder\n",
    "qc_list_bids_csv . --mask-patterns-base derivatives/masks/ --out-csv bids.csv --mask-patterns \"sub-{subject}_mask.nii.gz\" --suffix T1w # index the folder\n",
    "qc_generate_reports derivatives/reports bids.csv # generate the reports\n",
    "# mine\n",
    "qc_list_bids_csv /home/jaimebarranco/Desktop/samples_v3_bids --mask-patterns-base /home/jaimebarranco/Desktop/samples_v3_bids/derivatives/masks/ --mask-patterns \"sub-{subject}_mask.nii.gz\" --suffix T1w --out-csv /home/jaimebarranco/Desktop/fetal_qc_output/bids_csv.csv\n",
    "qc_generate_reports /home/jaimebarranco/Desktop/fetal_qc_output/ /home/jaimebarranco/Desktop/fetal_qc_output/bids_csv.csv # outpath bids.csv\n",
    "qc_generate_index /home/jaimebarranco/Desktop/fetal_qc_output/ # generate index.html\n",
    "# test\n",
    "qc_list_bids_csv /home/jaimebarranco/Desktop/samples_v3_bids_test --mask-patterns-base /home/jaimebarranco/Desktop/samples_v3_bids_test/derivatives/masks/ --mask-patterns \"sub-{subject}_mask.nii.gz\" --suffix T1w --out-csv /home/jaimebarranco/Desktop/fetal_qc_output_test/bids_csv.csv\n",
    "qc_generate_reports /home/jaimebarranco/Desktop/fetal_qc_output_test/ /home/jaimebarranco/Desktop/fetal_qc_output_test/bids_csv.csv # outpath bids.csv\n",
    "# pipeline\n",
    "qc_run_pipeline --bids_dir /home/jaimebarranco/Desktop/samples_v3_bids --out_path /home/jaimebarranco/Desktop/fetal_qc_output/ --mask-patterns-base /home/jaimebarranco/Desktop/samples_v3_bids/derivatives/masks/ --mask-patterns \"sub-{subject}_mask.nii.gz\" --suffix T1w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MREye-QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# mreye-qc\n",
    "docker run -it --rm -v /home/jaimebarranco/Desktop/samples_v3_bids:/data:ro -v /home/jaimebarranco/Desktop/mreyeqc_output:/out mreyeqc:latest /data /out participant --participant_label 001 --nprocs 12 --omp-nthreads 12\n",
    "# 7bd99c588704826d399898ec1f7419d40dc09b27473d511066f3cf8ab097fe5a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "# def run_command(command):\n",
    "#     process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "#     console_output, console_errors = process.communicate()\n",
    "\n",
    "def run_command(command):\n",
    "    os.system(command)\n",
    "\n",
    "input_folder = '/home/jaimebarranco/Desktop/samples_v3_bids'\n",
    "output_folder = '/home/jaimebarranco/Desktop/mreyeqc_output'\n",
    "n_procs = 12\n",
    "n_threads = 12\n",
    "\n",
    "n_sub = [f.path for f in os.scandir(input_folder) if f.is_dir() and f.name.startswith('sub-')] # number of subjects in input folder\n",
    "n_sub = len(n_sub)\n",
    "print(f'Number of subjects: {n_sub}')\n",
    "\n",
    "# Run MRIQC for each subject\n",
    "for sub in range(1, 6):\n",
    "    command = f'docker run --rm -v {input_folder}:/data:ro -v {output_folder}:/out mreyeqc_test:latest /data /out participant --participant_label {sub+1:03} --nprocs {n_procs} --omp-nthreads {n_threads}'\n",
    "    print(command)\n",
    "    run_command(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run MRIQC group analysis\n",
    "command = f'docker run --rm -v {input_folder}:/data:ro -v {output_folder}:/out mreyeqc_test:latest /data /out group'\n",
    "print(command)\n",
    "run_command(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='mriqc_eye_mask')\n",
    "\n",
    "# metrics\n",
    "meri = df['quality'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% confidence interval: snr_csf, summary_csf_mean, summary_wm_mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects outside the 95% confidence interval for qi_2\n",
    "relevant_metrics = [snr_csf, summary_csf_mean, summary_wm_mad]\n",
    "relevant_metrics_name = ['snr_csf', 'summary_csf_mean', 'summary_wm_mad']\n",
    "\n",
    "for i in range(len(relevant_metrics)):\n",
    "    print(f'\\n{relevant_metrics_name[i]}')\n",
    "    mean = np.mean(relevant_metrics[i])\n",
    "    std = np.std(relevant_metrics[i])\n",
    "    lower = mean - 2*std\n",
    "    upper = mean + 2*std\n",
    "    print(f'Lower: {lower}, Upper: {upper}')\n",
    "    for j in range(len(relevant_metrics[i])):\n",
    "        if relevant_metrics[i][j] < lower or relevant_metrics[i][j] > upper:\n",
    "            print(f'{j+1:03} - {relevant_metrics[i][j]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Meri - Bene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating: r^2 = 0.7436, p-value = 8.139e-16\n",
      "blur: r^2 = 0.5103, p-value = 8.28e-07\n",
      "noise: r^2 = 0.52, p-value = 4.699e-07\n",
      "motion: r^2 = 0.4279, p-value = 5.464e-05\n",
      "bgair: r^2 = 0.5281, p-value = 2.892e-07\n",
      "eyes_closed: r^2 = 0.07868, p-value = 0.4795\n",
      "eyes_closed: 66.27%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df_meri = pd.read_csv('/home/jaimebarranco/Desktop/SHIP_QCmri_MBC/ratings.csv')\n",
    "df_bene = pd.read_csv('/home/jaimebarranco/Desktop/Evaluations_frb/ratings.csv')\n",
    "\n",
    "# metrics meri\n",
    "rating_meri = df_meri['rating'].to_numpy()\n",
    "blur_meri = df_meri['blur'].to_numpy()\n",
    "noise_meri = df_meri['noise'].to_numpy()\n",
    "motion_meri = df_meri['motion'].to_numpy()\n",
    "bgair_meri = df_meri['bgair'].to_numpy()\n",
    "eyes_closed_meri = np.where(df_meri['artifacts'].to_numpy() == \"['eyes-closed']\", 1, 0)\n",
    "# selected_slices_meri = df_meri['selected_slices'].to_numpy()\n",
    "\n",
    "# metrics bene\n",
    "rating_bene = df_bene['rating'].to_numpy()\n",
    "blur_bene = df_bene['blur'].to_numpy()\n",
    "noise_bene = df_bene['noise'].to_numpy()\n",
    "motion_bene = df_bene['motion'].to_numpy()\n",
    "bgair_bene = df_bene['bgair'].to_numpy()\n",
    "eyes_closed_bene = np.where(df_bene['artifacts'].to_numpy() == \"['eyes-closed']\", 1, 0)\n",
    "# selected_slices_bene = df_bene['selected_slices'].to_numpy()\n",
    "\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics_meri = [rating_meri, blur_meri, noise_meri, motion_meri, bgair_meri, eyes_closed_meri] #, selected_slices_meri]\n",
    "metrics_bene = [rating_bene, blur_bene, noise_bene, motion_bene, bgair_bene, eyes_closed_bene] #, selected_slices_bene]\n",
    "metrics_names = ['rating', 'blur', 'noise', 'motion', 'bgair', 'eyes_closed'] #, 'selected_slices']\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and Bene\n",
    "for i in range(len(metrics_meri)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(metrics_meri[i], metrics_bene[i])\n",
    "    # if p_value < ALPHA:\n",
    "    print(f'{metrics_names[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# Eyes closed correlation\n",
    "sum = 0\n",
    "for i in range(len(eyes_closed_meri)):\n",
    "    if eyes_closed_meri[i] == eyes_closed_bene[i]: sum += 1 \n",
    "print(f'eyes_closed: {np.round(sum/len(eyes_closed_meri)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainmask - Meri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics correlation with Meri's ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality: r^2 = 1.0, p-value = 0.0\n",
      "size_z: r^2 = 0.2271, p-value = 0.03894\n",
      "summary_bg_k: r^2 = -0.2219, p-value = 0.04379\n",
      "summary_gm_mean: r^2 = -0.3131, p-value = 0.003957\n",
      "summary_gm_n: r^2 = -0.2609, p-value = 0.0172\n",
      "summary_wm_k: r^2 = -0.2303, p-value = 0.03619\n",
      "summary_wm_mean: r^2 = -0.2242, p-value = 0.04156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaimebarranco/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='mreyeqc_brainmask_meri')\n",
    "\n",
    "# metrics\n",
    "meri = df['rating'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CI95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary_bg_k\n",
      "Lower: -14.583927872351477, Upper: 37.4560750404094\n",
      "037 - 40.6587548340778\n",
      "039 - 116.978478093923\n",
      "065 - 43.2225229839192\n",
      "\n",
      "summary_gm_mean\n",
      "Lower: 749.1098498409962, Upper: 787.1616628310477\n",
      "010 - 787.876496823232\n",
      "020 - 787.188546087105\n",
      "028 - 746.896190266065\n",
      "061 - 745.498012687434\n",
      "062 - 746.329037996085\n",
      "\n",
      "summary_gm_n\n",
      "Lower: 6143.864737424969, Upper: 28151.605142093103\n",
      "002 - 29983\n",
      "003 - 32370\n",
      "054 - 33012\n",
      "\n",
      "summary_wm_k\n",
      "Lower: 0.1620723086873081, Upper: 0.818487684432192\n",
      "016 - 0.120161022991804\n",
      "022 - 0.821862467532863\n",
      "038 - 0.82305761471255\n",
      "048 - 0.85217867265451\n",
      "050 - 0.90011624279788\n",
      "062 - 0.822211147938027\n",
      "081 - 1.03999070604355\n",
      "\n",
      "summary_wm_mean\n",
      "Lower: 1001.9101787060507, Upper: 1006.4046900103632\n",
      "036 - 1006.57452224029\n"
     ]
    }
   ],
   "source": [
    "# subjects outside the 95% confidence interval for qi_2\n",
    "relevant_metrics = [summary_bg_k, summary_gm_mean, summary_gm_n, summary_wm_k, summary_wm_mean]\n",
    "relevant_metrics_name = ['summary_bg_k', 'summary_gm_mean', 'summary_gm_n', 'summary_wm_k', 'summary_wm_mean']\n",
    "\n",
    "for i in range(len(relevant_metrics)):\n",
    "    print(f'\\n{relevant_metrics_name[i]}')\n",
    "    mean = np.mean(relevant_metrics[i])\n",
    "    std = np.std(relevant_metrics[i])\n",
    "    lower = mean - 2*std\n",
    "    upper = mean + 2*std\n",
    "    print(f'Lower: {lower}, Upper: {upper}')\n",
    "    for j in range(len(relevant_metrics[i])):\n",
    "        if relevant_metrics[i][j] < lower or relevant_metrics[i][j] > upper:\n",
    "            print(f'{j+1:03} - {relevant_metrics[i][j]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainmask - Bene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics correlation with Bene's ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality: r^2 = 1.0, p-value = 0.0\n",
      "cnr: r^2 = 0.2242, p-value = 0.04161\n",
      "summary_bg_median: r^2 = -0.2265, p-value = 0.03947\n",
      "summary_gm_k: r^2 = -0.2206, p-value = 0.04507\n",
      "summary_gm_mean: r^2 = -0.2832, p-value = 0.009473\n",
      "summary_gm_n: r^2 = -0.2364, p-value = 0.03141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaimebarranco/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='mreyeqc_brainmask_bene')\n",
    "\n",
    "# metrics\n",
    "meri = df['rating'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CI95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cnr\n",
      "Lower: 2.5256336293545703, Upper: 3.51481117653755\n",
      "015 - 3.5193756625607\n",
      "061 - 3.58777080768549\n",
      "\n",
      "summary_bg_median\n",
      "Lower: 0.8175354972981421, Upper: 7.086051898857489\n",
      "003 - 0.0\n",
      "029 - 0.0\n",
      "034 - 0.0\n",
      "037 - 0.0\n",
      "047 - 0.0\n",
      "050 - 0.0\n",
      "051 - 0.0\n",
      "065 - 0.0\n",
      "\n",
      "summary_gm_k\n",
      "Lower: -0.14862775506176742, Upper: 0.207331339712489\n",
      "001 - 0.211930893862272\n",
      "016 - 0.222340679813799\n",
      "023 - 0.230171698554317\n",
      "035 - 0.28360445106391\n",
      "054 - -0.170411915886417\n",
      "\n",
      "summary_gm_mean\n",
      "Lower: 749.1098498409962, Upper: 787.1616628310477\n",
      "010 - 787.876496823232\n",
      "020 - 787.188546087105\n",
      "028 - 746.896190266065\n",
      "061 - 745.498012687434\n",
      "062 - 746.329037996085\n",
      "\n",
      "summary_gm_n\n",
      "Lower: 6143.864737424969, Upper: 28151.605142093103\n",
      "002 - 29983\n",
      "003 - 32370\n",
      "054 - 33012\n"
     ]
    }
   ],
   "source": [
    "# subjects outside the 95% confidence interval for qi_2\n",
    "relevant_metrics = [cnr, summary_bg_median, summary_gm_k, summary_gm_mean, summary_gm_n]\n",
    "relevant_metrics_name = ['cnr', 'summary_bg_median', 'summary_gm_k', 'summary_gm_mean', 'summary_gm_n']\n",
    "\n",
    "for i in range(len(relevant_metrics)):\n",
    "    print(f'\\n{relevant_metrics_name[i]}')\n",
    "    mean = np.mean(relevant_metrics[i])\n",
    "    std = np.std(relevant_metrics[i])\n",
    "    lower = mean - 2*std\n",
    "    upper = mean + 2*std\n",
    "    print(f'Lower: {lower}, Upper: {upper}')\n",
    "    for j in range(len(relevant_metrics[i])):\n",
    "        if relevant_metrics[i][j] < lower or relevant_metrics[i][j] > upper:\n",
    "            print(f'{j+1:03} - {relevant_metrics[i][j]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyemask - Meri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality: r^2 = 1.0, p-value = 0.0\n",
      "summary_csf_mean: r^2 = -0.2537, p-value = 0.02064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaimebarranco/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='mreyeqc_eyemask_meri')\n",
    "\n",
    "# metrics\n",
    "meri = df['rating'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CI95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary_csf_mean\n",
      "Lower: 383.270363659152, Upper: 518.2389633130906\n",
      "006 - 545.550482497902\n",
      "008 - 372.054525300511\n",
      "031 - 378.030537036904\n",
      "058 - 552.119631097792\n"
     ]
    }
   ],
   "source": [
    "# subjects outside the 95% confidence interval for qi_2\n",
    "relevant_metrics = [summary_csf_mean]\n",
    "relevant_metrics_name = ['summary_csf_mean']\n",
    "\n",
    "for i in range(len(relevant_metrics)):\n",
    "    print(f'\\n{relevant_metrics_name[i]}')\n",
    "    mean = np.mean(relevant_metrics[i])\n",
    "    std = np.std(relevant_metrics[i])\n",
    "    lower = mean - 2*std\n",
    "    upper = mean + 2*std\n",
    "    print(f'Lower: {lower}, Upper: {upper}')\n",
    "    for j in range(len(relevant_metrics[i])):\n",
    "        if relevant_metrics[i][j] < lower or relevant_metrics[i][j] > upper:\n",
    "            print(f'{j+1:03} - {relevant_metrics[i][j]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyemask - Bene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality: r^2 = 1.0, p-value = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaimebarranco/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# read an excel file in .xlsx format\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/scores.xlsx', sheet_name='mreyeqc_eyemask_bene')\n",
    "\n",
    "# metrics\n",
    "meri = df['rating'].to_numpy()\n",
    "cjv = df['cjv'].to_numpy()\n",
    "cnr = df['cnr'].to_numpy()\n",
    "efc = df['efc'].to_numpy()\n",
    "fber = df['fber'].to_numpy()\n",
    "fwhm_avg = df['fwhm_avg'].to_numpy()\n",
    "fwhm_x = df['fwhm_x'].to_numpy()\n",
    "fwhm_y = df['fwhm_y'].to_numpy()\n",
    "fwhm_z = df['fwhm_z'].to_numpy()\n",
    "icvs_csf = df['icvs_csf'].to_numpy()\n",
    "icvs_gm = df['icvs_gm'].to_numpy()\n",
    "icvs_wm = df['icvs_wm'].to_numpy()\n",
    "inu_med = df['inu_med'].to_numpy()\n",
    "inu_range = df['inu_range'].to_numpy()\n",
    "qi_1 = df['qi_1'].to_numpy()\n",
    "qi_2 = df['qi_2'].to_numpy()\n",
    "rpve_csf = df['rpve_csf'].to_numpy()\n",
    "rpve_gm = df['rpve_gm'].to_numpy()\n",
    "rpve_wm = df['rpve_wm'].to_numpy()\n",
    "snr_csf = df['snr_csf'].to_numpy()\n",
    "snr_gm = df['snr_gm'].to_numpy()\n",
    "snr_total = df['snr_total'].to_numpy()\n",
    "snr_wm = df['snr_wm'].to_numpy()\n",
    "snrd_csf = df['snrd_csf'].to_numpy()\n",
    "snrd_gm = df['snrd_gm'].to_numpy()\n",
    "snrd_total = df['snrd_total'].to_numpy()\n",
    "snrd_wm = df['snrd_wm'].to_numpy()\n",
    "summary_bg_k = df['summary_bg_k'].to_numpy()\n",
    "summary_bg_mad = df['summary_bg_mad'].to_numpy()\n",
    "summary_bg_mean = df['summary_bg_mean'].to_numpy()\n",
    "summary_bg_median = df['summary_bg_median'].to_numpy()\n",
    "summary_bg_n = df['summary_bg_n'].to_numpy()\n",
    "summary_bg_p05 = df['summary_bg_p05'].to_numpy()\n",
    "summary_bg_p95 = df['summary_bg_p95'].to_numpy()\n",
    "summary_bg_stdv = df['summary_bg_stdv'].to_numpy()\n",
    "summary_csf_k = df['summary_csf_k'].to_numpy()\n",
    "summary_csf_mad = df['summary_csf_mad'].to_numpy()\n",
    "summary_csf_mean = df['summary_csf_mean'].to_numpy()\n",
    "summary_csf_median = df['summary_csf_median'].to_numpy()\n",
    "summary_csf_n = df['summary_csf_n'].to_numpy()\n",
    "summary_csf_p05 = df['summary_csf_p05'].to_numpy()\n",
    "summary_csf_p95 = df['summary_csf_p95'].to_numpy()\n",
    "summary_csf_stdv = df['summary_csf_stdv'].to_numpy()\n",
    "summary_gm_k = df['summary_gm_k'].to_numpy()\n",
    "summary_gm_mad = df['summary_gm_mad'].to_numpy()\n",
    "summary_gm_mean = df['summary_gm_mean'].to_numpy()\n",
    "summary_gm_median = df['summary_gm_median'].to_numpy()\n",
    "summary_gm_n = df['summary_gm_n'].to_numpy()\n",
    "summary_gm_p05 = df['summary_gm_p05'].to_numpy()\n",
    "summary_gm_p95 = df['summary_gm_p95'].to_numpy()\n",
    "summary_gm_stdv = df['summary_gm_stdv'].to_numpy()\n",
    "summary_wm_k = df['summary_wm_k'].to_numpy()\n",
    "summary_wm_mad = df['summary_wm_mad'].to_numpy()\n",
    "summary_wm_mean = df['summary_wm_mean'].to_numpy()\n",
    "summary_wm_median = df['summary_wm_median'].to_numpy()\n",
    "summary_wm_n = df['summary_wm_n'].to_numpy()\n",
    "summary_wm_p05 = df['summary_wm_p05'].to_numpy()\n",
    "summary_wm_p95 = df['summary_wm_p95'].to_numpy()\n",
    "summary_wm_stdv = df['summary_wm_stdv'].to_numpy()\n",
    "tpm_overlap_csf = df['tpm_overlap_csf'].to_numpy()\n",
    "tpm_overlap_gm = df['tpm_overlap_gm'].to_numpy()\n",
    "tpm_overlap_wm = df['tpm_overlap_wm'].to_numpy()\n",
    "wm2max = df['wm2max'].to_numpy()\n",
    "\n",
    "# add all the metrics above to a list\n",
    "metrics = [meri, cjv, cnr, efc, fber, fwhm_avg, fwhm_x, fwhm_y, fwhm_z, icvs_csf, icvs_gm, icvs_wm, inu_med, inu_range, qi_1, qi_2, rpve_csf, rpve_gm, rpve_wm, snr_csf, snr_gm, snr_total, snr_wm, snrd_csf, snrd_gm, snrd_total, snrd_wm, summary_bg_k, summary_bg_mad, summary_bg_mean, summary_bg_median, summary_bg_n, summary_bg_p05, summary_bg_p95, summary_bg_stdv, summary_csf_k, summary_csf_mad, summary_csf_mean, summary_csf_median, summary_csf_n, summary_csf_p05, summary_csf_p95, summary_csf_stdv, summary_gm_k, summary_gm_mad, summary_gm_mean, summary_gm_median, summary_gm_n, summary_gm_p05, summary_gm_p95, summary_gm_stdv, summary_wm_k, summary_wm_mad, summary_wm_mean, summary_wm_median, summary_wm_n, summary_wm_p05, summary_wm_p95, summary_wm_stdv, tpm_overlap_csf, tpm_overlap_gm, tpm_overlap_wm, wm2max]\n",
    "metrics_name = [i for i in df.columns if i not in ['subject', 'sub number', 'comments', 'Sex', 'Age', 'Height', 'Weight', 'BMI', 'axial_length']]\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# correlation between Meri and all the metrics\n",
    "for i in range(len(metrics)):\n",
    "    # R-squared measures the proportion of the variance in one variable that is predictable from the other variable.\n",
    "    # p_value is a measure of the evidence against a null hypothesis. A small p-value indicates strong evidence against the null hypothesis, while a large p-value indicates weak evidence against the null hypothesis \n",
    "    r_squared, p_value = stats.pearsonr(meri, metrics[i])\n",
    "    if p_value < ALPHA:\n",
    "        print(f'{metrics_name[i]}: r^2 = {r_squared:.4}, p-value = {p_value:.4}')\n",
    "\n",
    "# plot Meri vs. all the metrics\n",
    "# for i in range(len(metrics)):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(meri, metrics[i])\n",
    "#     plt.xlabel('Meri')\n",
    "#     plt.ylabel(metrics_name[i])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CI95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary_csf_mean\n",
      "Lower: 383.270363659152, Upper: 518.2389633130906\n",
      "006 - 545.550482497902\n",
      "008 - 372.054525300511\n",
      "031 - 378.030537036904\n",
      "058 - 552.119631097792\n"
     ]
    }
   ],
   "source": [
    "# subjects outside the 95% confidence interval for qi_2\n",
    "relevant_metrics = [summary_csf_mean]\n",
    "relevant_metrics_name = ['summary_csf_mean']\n",
    "\n",
    "for i in range(len(relevant_metrics)):\n",
    "    print(f'\\n{relevant_metrics_name[i]}')\n",
    "    mean = np.mean(relevant_metrics[i])\n",
    "    std = np.std(relevant_metrics[i])\n",
    "    lower = mean - 2*std\n",
    "    upper = mean + 2*std\n",
    "    print(f'Lower: {lower}, Upper: {upper}')\n",
    "    for j in range(len(relevant_metrics[i])):\n",
    "        if relevant_metrics[i][j] < lower or relevant_metrics[i][j] > upper:\n",
    "            print(f'{j+1:03} - {relevant_metrics[i][j]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
