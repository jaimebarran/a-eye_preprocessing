{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather all the analysed subjects (quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=83 cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df1 = pd.read_excel('/mnt/sda1/Repos/a-eye/Output/mri_qc/scores.xlsx', sheet_name='brainmask_avg_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add another column which is the opposite of 'exclusion' column\n",
    "ratings_df1['rate'] = ratings_df1['exclusion'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# remove all the columns except for 'subject' and 'rate'\n",
    "ratings_df1 = ratings_df1[['subject', 'rate', 'rating_text']]\n",
    "\n",
    "# sort by 'name'\n",
    "ratings_df1 = ratings_df1.sort_values(by=['subject'])\n",
    "ratings_df1['subject'] = ratings_df1['subject'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bids name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2090153/1119983443.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3['bids_name'] = bids_names # add bids names\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get bids name\n",
    "'''\n",
    "subs_ls = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset/non_labeled_dataset_nifti'\n",
    "files_1 = [(os.path.basename(f)).split('.')[0] for f in sorted(os.listdir(subs_ls)) if not f.startswith('.')]\n",
    "files_1 = [int(f) for f in files_1] # files from string to int\n",
    "numbers_1 = [f for f in range(1, len(files_1)+1)]\n",
    "df_1 = pd.DataFrame({'Subject': files_1, 'Number': numbers_1})\n",
    "\n",
    "subs = '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/samples_v3'\n",
    "files_2 = [(os.path.basename(f)).split('.')[0] for f in sorted(os.listdir(subs)) if not f.startswith('.')]\n",
    "files_2 = [int(f) for f in files_2] # files from string to int\n",
    "numbers_2 = [f for f in range(1, len(files_2)+1)]\n",
    "df_2 = pd.DataFrame({'Subject': files_2, 'Number': numbers_2})\n",
    "\n",
    "# df_1 only with df_2 subjects\n",
    "df_3 = df_1[df_1['Subject'].isin(df_2['Subject'])]\n",
    "numbers_3 = df_3['Number']\n",
    "bids_names = [f'sub-{n:03}_T1w' for n in numbers_3]\n",
    "df_3['bids_name'] = bids_names # add bids names\n",
    "df_3 = df_3.reset_index(drop=True) # reset index\n",
    "df_3 = df_3.sort_values(by=['Subject']) # sort by 'Subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'bids_name' column from df_3 to ratings_df1\n",
    "ratings_df1['bids_name'] = df_3['bids_name'].values\n",
    "ratings_df1 = ratings_df1.sort_values(by=['bids_name'])\n",
    "ratings_df1 = ratings_df1.reset_index(drop=True) # reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move columns\n",
    "ratings_df1.insert(0, 'bids_name', ratings_df1.pop('bids_name'))\n",
    "ratings_df1 = ratings_df1[['bids_name', 'rate', 'rating_text']]\n",
    "ratings_df1 = ratings_df1.rename(columns={'rating_text': 'comments'})\n",
    "ratings_df1['bids_name'] = ratings_df1['bids_name'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reports name from LS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_csv = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/fetal/fetalqc_non-labeled-dataset/bids_csv.csv\")\n",
    "bids_csv['im'] = bids_csv['im'].apply(lambda x: x.split('/')[-1].split('_')[0])\n",
    "# rename 'im' column to 'bids_name'\n",
    "bids_csv = bids_csv.rename(columns={'im': 'bids_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subset of bids_csv where 'name' is present\n",
    "bids_csv_name = bids_csv[bids_csv['name'].notnull()]\n",
    "# merge ratings_df1 and bids_csv_name on 'bids_name'\n",
    "merged_df1 = pd.merge(ratings_df1, bids_csv_name, on='bids_name')\n",
    "# add the 'name' column from bids_csv_name to ratings_df1\n",
    "ratings_df1['name'] = merged_df1['name']\n",
    "# reorder columns\n",
    "ratings_df1.insert(1, 'name', ratings_df1.pop('name'))\n",
    "# order by 'name'\n",
    "ratings_df1 = ratings_df1.sort_values(by=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df1 = ratings_df1.rename(columns={'name': 'report_name'})\n",
    "ratings_df1 = ratings_df1.reset_index(drop=True) # reset index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=100 cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "excluded_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df2 = pd.read_excel('/mnt/sda1/Repos/a-eye/Output/mri_qc/excluded_edited.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where 'my_rate' is nan\n",
    "ratings_df2 = ratings_df2[ratings_df2['my_rate'].notnull()]\n",
    "# keeping only the columns we want\n",
    "ratings_df2 = ratings_df2[['subject_name', 'bids_name', 'my_rate', 'Comments']]\n",
    "# reorder columns\n",
    "ratings_df2.insert(0, 'bids_name', ratings_df2.pop('bids_name'))\n",
    "# renaming columns\n",
    "ratings_df2 = ratings_df2.rename(columns={'subject_name': 'report_name', 'my_rate': 'rate', 'Comments': 'comments'})\n",
    "# changing rate according to mriqc-learn\n",
    "ratings_df2['rate'] = ratings_df2['rate'].apply(lambda x: 1 if x == 0 else 0)\n",
    "# changing bids_name\n",
    "ratings_df2['bids_name'] = ratings_df2['bids_name'].apply(lambda x: x.split('_')[0])\n",
    "# order by 'name'\n",
    "ratings_df2 = ratings_df2.sort_values(by=['report_name'])\n",
    "ratings_df2 = ratings_df2.reset_index(drop=True) # reset index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common subs between dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bids_name report_name  rate   comments\n",
      "0  sub-1049   sub-PKFEK     1       Poor\n",
      "1  sub-1155   sub-UOVLU     1  Excellent\n",
      "  bids_name report_name  rate comments\n",
      "0  sub-1049   sub-PKFEK     1      NaN\n",
      "1  sub-1155   sub-UOVLU     1      NaN\n"
     ]
    }
   ],
   "source": [
    "# count how many elements are in common between ratings_df1 and ratings_df2 by 'report_name'\n",
    "common_df1_df2 = ratings_df1[ratings_df1['report_name'].isin(ratings_df2['report_name'])]\n",
    "common_df1_df2 = common_df1_df2.sort_values(by=['report_name'])\n",
    "common_df1_df2 = common_df1_df2.reset_index(drop=True) # reset index\n",
    "print(common_df1_df2)\n",
    "\n",
    "common_df2_df1 = ratings_df2[ratings_df2['report_name'].isin(ratings_df1['report_name'])]\n",
    "common_df2_df1 = common_df2_df1.sort_values(by=['report_name'])\n",
    "common_df2_df1 = common_df2_df1.reset_index(drop=True) # reset index\n",
    "print(common_df2_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(common_df1_df2)):\n",
    "    if common_df1_df2['rate'].values[i] != common_df2_df1['rate'].values[i]:\n",
    "        print(f'{common_df1_df2[\"report_name\"].values[i]} has {common_df1_df2[\"rate\"].values[i]} in excel1 and {common_df2_df1[\"rate\"].values[i]} in excel2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat ratings_df1 and ratings_df2. If 'rate' is different in both, the value from ratings_df1 will be used\n",
    "ratings_df = pd.concat([ratings_df1, ratings_df2])\n",
    "ratings_df = ratings_df.sort_values(by=['report_name'])\n",
    "ratings_df = ratings_df.reset_index(drop=True) # reset index\n",
    "ratings_df = ratings_df.drop_duplicates(subset=['report_name'], keep='first') # drop duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All other excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "excels = [\n",
    "    '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/excluded_mriqclearn.xlsx',\n",
    "    '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/excluded_mriqclearn_N183_NoBrainIQMs_th043.xlsx',\n",
    "    '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/excluded_mriqclearn_N183_NoBrainIQMs_th0389.xlsx',\n",
    "    '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/excluded_mriqclearn_NoBrainIQMs_th0336.xlsx',\n",
    "    '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/excluded_mriqclearn_trN183_th0753.xlsx',\n",
    "    '/mnt/sda1/Repos/a-eye/Output/mri_qc/output_classifiers/excluded_N183_NoBrainIQMs.xlsx',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    '''\n",
    "    Preprocess the dataframe\n",
    "    '''\n",
    "    # remove rows where 'my_rate' is nan\n",
    "    df = df[df['my_rate'].notnull()]\n",
    "    # renaming columns\n",
    "    df = df.rename(columns={'name': 'report_name', 'my_rate': 'rate'})\n",
    "    # changing bids_name\n",
    "    df['bids_name'] = df['bids_name'].apply(lambda x: x.split('_')[0])\n",
    "    # order by 'name'\n",
    "    df = df.sort_values(by=['report_name'])\n",
    "    df = df.reset_index(drop=True) # reset index\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dataframes altogether excluding subjects with different rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(df_list):\n",
    "    '''\n",
    "    Merge a list of dataframes keeping the rate from the first dataframe in case of conflict\n",
    "    '''\n",
    "    # concat all dataframes in the list\n",
    "    df_aux = pd.concat(df_list)\n",
    "    df_aux = df_aux.sort_values(by=['report_name'])\n",
    "    df_aux = df_aux.reset_index(drop=True) # reset index\n",
    "    duplicates = df_aux[df_aux.duplicated(subset=['report_name'], keep=False)]\n",
    "    df_aux = df_aux.drop_duplicates(subset=['report_name'], keep='first') # drop duplicates choosing the first one\n",
    "    df = df_aux\n",
    "\n",
    "    # keep track of duplicates with different rates\n",
    "    common_subs = duplicates[duplicates.duplicated(subset=['report_name'], keep=False)]\n",
    "    common_subs = common_subs.sort_values(by=['report_name'])\n",
    "    common_subs = common_subs.reset_index(drop=True)\n",
    "\n",
    "    # filter diff_rates to only include duplicates where rate differs\n",
    "    diff_rates = common_subs[~common_subs.duplicated(subset=['report_name', 'rate'], keep=False)]\n",
    "    diff_rates = diff_rates.drop_duplicates(subset=['report_name'], keep='first')\n",
    "    diff_rates = diff_rates.drop(columns=['rate', 'comments'])\n",
    "    diff_rates = diff_rates.sort_values(by=['report_name'])\n",
    "    diff_rates = diff_rates.reset_index(drop=True)\n",
    "\n",
    "    return df, common_subs, diff_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get subjects with different rates between dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_common_diff(df1, df2):\n",
    "    '''\n",
    "    Merge common_subs and diff_rates dataframes on 'report_name' column\n",
    "    '''\n",
    "    merged_df = pd.merge(df2, df1[['report_name']], on='report_name', how='inner')\n",
    "    print(merged_df)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and preprocess excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_aux = [ratings_df]\n",
    "for ex in range(len(excels)):\n",
    "    globals()['ratings_df%s' % str(ex+3)] = pd.read_excel(excels[ex])\n",
    "    globals()['ratings_df%s' % str(ex+3)] = preprocess_df(globals()['ratings_df%s' % str(ex+3)])\n",
    "    ratings_df_aux.append(globals()['ratings_df%s' % str(ex+3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get common subjects and rates that differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_df_dfaux, common_dfaux_df = get_common_subs(ratings_df, ratings_df_aux)\n",
    "# ratings_df, common_subs, diff_rates = merge_dataframes(ratings_df, ratings_df3, ratings_df4, ratings_df5, ratings_df6, ratings_df7)\n",
    "ratings_df, common_subs, diff_rates = merge_dataframes(ratings_df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy reports to an output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, shutil\n",
    "\n",
    "# reports_folder = '/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset'\n",
    "# output_folder = '/home/jaimebarranco/Downloads/all_excluded'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# # copy html reports from reports_folder that match the subjects in excluded dataframe to output_folder\n",
    "# for i in range(len(ratings_df)):\n",
    "#     subject = ratings_df['report_name'].values[i]\n",
    "#     for filename in os.listdir(reports_folder):\n",
    "#         if filename.startswith(f'{subject}_report'):\n",
    "#             shutil.copy(f'{reports_folder}/{filename}', f'{output_folder}/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get subjects with different rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bids_name report_name  rate                             comments\n",
      "0    sub-705   sub-AYXLO     1                                  NaN\n",
      "1    sub-705   sub-AYXLO     0                                  NaN\n",
      "2    sub-451   sub-LYRAA     1                            eyes open\n",
      "3    sub-451   sub-LYRAA     1                                poor \n",
      "4    sub-451   sub-LYRAA     1                                weird\n",
      "5    sub-451   sub-LYRAA     0                       limit, no o.n.\n",
      "6    sub-363   sub-MHRGQ     0                blurred lens, no o.n.\n",
      "7    sub-363   sub-MHRGQ     1                  bad lens, artifacts\n",
      "8    sub-147   sub-OOJUF     1                                 poor\n",
      "9    sub-147   sub-OOJUF     0                                  NaN\n",
      "10   sub-100   sub-OQIYU     1                      almost no lens \n",
      "11   sub-100   sub-OQIYU     0                      almost no lens \n",
      "12   sub-329   sub-QFTJV     1  limit, bottom part of the eyes open\n",
      "13   sub-329   sub-QFTJV     0              open during acquisition\n",
      "14   sub-069   sub-UKODB     0                                  NaN\n",
      "15   sub-069   sub-UKODB     1                                 poor\n",
      "16  sub-1040   sub-VWNXG     1                            very poor\n",
      "17  sub-1040   sub-VWNXG     0                              Exclude\n",
      "18   sub-053   sub-XKICG     1                                 poor\n",
      "19   sub-053   sub-XKICG     0                          blur, noise\n",
      "20   sub-053   sub-XKICG     1                                limit\n",
      "21   sub-665   sub-ZSFPW     0                            open eyes\n",
      "22   sub-665   sub-ZSFPW     1                            eyes open\n",
      "23   sub-665   sub-ZSFPW     1                                  NaN\n"
     ]
    }
   ],
   "source": [
    "subs_diff_rate = merge_common_diff(diff_rates, common_subs) # subdataframe into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-AYXLO\n",
      "  bids_name report_name  rate comments\n",
      "0   sub-705   sub-AYXLO     1      NaN\n",
      "1   sub-705   sub-AYXLO     0      NaN\n",
      "percent agreement: \n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-LYRAA\n",
      "  bids_name report_name  rate        comments\n",
      "2   sub-451   sub-LYRAA     1       eyes open\n",
      "3   sub-451   sub-LYRAA     1           poor \n",
      "4   sub-451   sub-LYRAA     1           weird\n",
      "5   sub-451   sub-LYRAA     0  limit, no o.n.\n",
      "percent agreement: \n",
      "1    75.0\n",
      "0    25.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-MHRGQ\n",
      "  bids_name report_name  rate               comments\n",
      "6   sub-363   sub-MHRGQ     0  blurred lens, no o.n.\n",
      "7   sub-363   sub-MHRGQ     1    bad lens, artifacts\n",
      "percent agreement: \n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-OOJUF\n",
      "  bids_name report_name  rate comments\n",
      "8   sub-147   sub-OOJUF     1     poor\n",
      "9   sub-147   sub-OOJUF     0      NaN\n",
      "percent agreement: \n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-OQIYU\n",
      "   bids_name report_name  rate         comments\n",
      "10   sub-100   sub-OQIYU     1  almost no lens \n",
      "11   sub-100   sub-OQIYU     0  almost no lens \n",
      "percent agreement: \n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-QFTJV\n",
      "   bids_name report_name  rate                             comments\n",
      "12   sub-329   sub-QFTJV     1  limit, bottom part of the eyes open\n",
      "13   sub-329   sub-QFTJV     0              open during acquisition\n",
      "percent agreement: \n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-UKODB\n",
      "   bids_name report_name  rate comments\n",
      "14   sub-069   sub-UKODB     0      NaN\n",
      "15   sub-069   sub-UKODB     1     poor\n",
      "percent agreement: \n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-VWNXG\n",
      "   bids_name report_name  rate   comments\n",
      "16  sub-1040   sub-VWNXG     1  very poor\n",
      "17  sub-1040   sub-VWNXG     0    Exclude\n",
      "percent agreement: \n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-XKICG\n",
      "   bids_name report_name  rate     comments\n",
      "18   sub-053   sub-XKICG     1         poor\n",
      "19   sub-053   sub-XKICG     0  blur, noise\n",
      "20   sub-053   sub-XKICG     1        limit\n",
      "percent agreement: \n",
      "1    66.666667\n",
      "0    33.333333\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n",
      "sub-ZSFPW\n",
      "   bids_name report_name  rate   comments\n",
      "21   sub-665   sub-ZSFPW     0  open eyes\n",
      "22   sub-665   sub-ZSFPW     1  eyes open\n",
      "23   sub-665   sub-ZSFPW     1        NaN\n",
      "percent agreement: \n",
      "1    66.666667\n",
      "0    33.333333\n",
      "Name: rate, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Group the dataframe by report_name\n",
    "grouped = subs_diff_rate.groupby('report_name')\n",
    "\n",
    "for name, group in grouped:\n",
    "    print(name)\n",
    "    print(group)\n",
    "\n",
    "    # percent agreement for each group\n",
    "    percent_agreement = group['rate'].value_counts(normalize=True) * 100\n",
    "    print(f'percent agreement: \\n{percent_agreement}')\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '0' rates: 95/426\n"
     ]
    }
   ],
   "source": [
    "# count how many '0' rates are in ratings_df = real discarded subjects\n",
    "print(f\"Number of '0' rates: {len(ratings_df[ratings_df['rate'] == 0])}/{len(ratings_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_df removing rows where 'report_name' is in 'diff_rates'\n",
    "ratings_df_without_diff_rates = ratings_df[~ratings_df['report_name'].isin(diff_rates['report_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '0' rates: 93/416\n",
      "    bids_name report_name  rate                    comments\n",
      "1     sub-446   sub-AEHRL     0                     no lens\n",
      "16   sub-1001   sub-AXYOA     0                         NaN\n",
      "20    sub-024   sub-AZGFJ     0  weird image, lens diffused\n",
      "23    sub-473   sub-BDGIB     0                         NaN\n",
      "42    sub-138   sub-CEGVN     0                    no lens \n",
      "..        ...         ...   ...                         ...\n",
      "519   sub-016   sub-YTSAG     0             lens really bad\n",
      "532   sub-471   sub-ZBVUD     0             almost no lens \n",
      "552   sub-461   sub-ZUVLG     0           too noisy, blurry\n",
      "553   sub-459   sub-ZVWSY     0                    no lens \n",
      "555   sub-079   sub-ZZGVC     0                     Exclude\n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# count how many '0' rates are in ratings_df\n",
    "print(f\"Number of '0' rates: {len(ratings_df_without_diff_rates[ratings_df_without_diff_rates['rate'] == 0])}/{len(ratings_df_without_diff_rates)}\")\n",
    "\n",
    "# print those subjects (removing the subjects with different rates) ordered by bids_name\n",
    "print(ratings_df_without_diff_rates[ratings_df_without_diff_rates['rate'] == 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
